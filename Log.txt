> install.packages('keras')
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/Goutham/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/keras_2.2.4.1.zip'
Content type 'application/zip' length 3891054 bytes (3.7 MB)
downloaded 3.7 MB

package ‘keras’ successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\Goutham\AppData\Local\Temp\RtmpcNkPoK\downloaded_packages
> intall.packages('Rtools')
Error in intall.packages("Rtools") : 
  could not find function "intall.packages"
> install.packages('tidyverse')
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/Goutham/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/tidyverse_1.2.1.zip'
Content type 'application/zip' length 93049 bytes (90 KB)
downloaded 90 KB

package ‘tidyverse’ successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\Goutham\AppData\Local\Temp\RtmpcNkPoK\downloaded_packages
> install.packages('tidyr')
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/Goutham/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/tidyr_1.0.0.zip'
Content type 'application/zip' length 1296146 bytes (1.2 MB)
downloaded 1.2 MB

package ‘tidyr’ successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\Goutham\AppData\Local\Temp\RtmpcNkPoK\downloaded_packages
> install.packages('EBImage')
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/Goutham/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
Warning in install.packages :
  package ‘EBImage’ is not available (for R version 3.6.1)
> install.packages('future')
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/Goutham/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/future_1.14.0.zip'
Content type 'application/zip' length 641543 bytes (626 KB)
downloaded 626 KB

package ‘future’ successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\Goutham\AppData\Local\Temp\RtmpcNkPoK\downloaded_packages
> install.packages('furr')
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/Goutham/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
Warning in install.packages :
  package ‘furr’ is not available (for R version 3.6.1)
> install.packages('furrr')
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/Goutham/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/furrr_0.1.0.zip'
Content type 'application/zip' length 110316 bytes (107 KB)
downloaded 107 KB

package ‘furrr’ successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\Goutham\AppData\Local\Temp\RtmpcNkPoK\downloaded_packages
> install.packages('caret')
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/Users/Goutham/Documents/R/win-library/3.6’
(as ‘lib’ is unspecified)
trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/caret_6.0-84.zip'
Content type 'application/zip' length 6237604 bytes (5.9 MB)
downloaded 5.9 MB

package ‘caret’ successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\Goutham\AppData\Local\Temp\RtmpcNkPoK\downloaded_packages
> library(keras)
> library(tidyverse)
-- Attaching packages --------------------------------------- tidyverse 1.2.1 --
v ggplot2 3.2.1     v purrr   0.3.2
v tibble  2.1.3     v dplyr   0.8.3
v tidyr   1.0.0     v stringr 1.4.0
v readr   1.3.1     v forcats 0.4.0
-- Conflicts ------------------------------------------ tidyverse_conflicts() --
x dplyr::filter() masks stats::filter()
x dplyr::lag()    masks stats::lag()
> 
> #if (!requireNamespace("BiocManager", quietly = TRUE))
> #  install.packages("BiocManager")
> 
> #BiocManager::install("EBImage")
> 
> library(EBImage)

Attaching package: ‘EBImage’

The following object is masked from ‘package:purrr’:

    transpose

> library(tidyr)
> library(future)

Attaching package: ‘future’

The following object is masked from ‘package:keras’:

    %<-%

> library(furrr)
> library(caret)
Loading required package: lattice

Attaching package: ‘caret’

The following object is masked from ‘package:future’:

    cluster

The following object is masked from ‘package:purrr’:

    lift

> 
> train_path <- './train'
> test_path <- './test'
> height <- 32
> width <- 32
> 
> labels <- read_csv('./train.csv')
Parsed with column specification:
cols(
  id = col_character(),
  has_cactus = col_double()
)
> test_ids <- data.frame(id = list.files(test_path)) %>% as_tibble()
> 
> preprocess_image <- function(file, path_, w, h){
+   image <- readImage(paste(path_,file, sep = '/'), type="jpeg")                         
+   image <- resize(image, w = w, h = h)  
+   image <- clahe(image)                               
+   image <- normalize(image)                                                            
+   imageData(image)                                    
+ }
> 
> list2tensor <- function(xList) {
+   xTensor <- simplify2array(xList)
+   aperm(xTensor, c(4, 1, 2, 3))    
+ }
> 
> get_images <- function(data, path_, w, h){
+   imgs <- data %>% select(id) %>% 
+     mutate(ImageData = future_map(id, ~preprocess_image(.,path_ = path_, w = w, h = h))) %>%
+     select(ImageData)
+   return(list2tensor(imgs$ImageData))
+ }
> 
> set.seed(1234)
> inTrain <- createDataPartition(labels$has_cactus, p = 0.9, list = FALSE)
> train_data <- labels[inTrain,]
> val_data <- labels[-inTrain,]
> y_train <- train_data$has_cactus
> y_val <- val_data$has_cactus
> 
> plan(multiprocess)
> X_train <- get_images(data = train_data, path_ = train_path, w = width, h = height)
> X_val <- get_images(data = val_data, path_ = train_path, w = width, h = height)
> X_test <- get_images(data = test_ids, path_ = test_path, w = width, h = height)
> 
> model <- keras_model_sequential()
> 
> model %>%
+   
+   layer_conv_2d(
+     filter = 32, kernel_size = c(3,3), padding = "same", 
+     input_shape = c(32, 32, 3)
+   ) %>%
+   layer_activation("relu") %>%
+   
+   layer_conv_2d(filter = 32, kernel_size = c(3,3)) %>%
+   layer_activation("relu") %>%
+   
+   layer_max_pooling_2d(pool_size = c(2,2)) %>%
+   layer_dropout(0.25) %>%
+   
+   layer_conv_2d(filter = 32, kernel_size = c(3,3), padding = "same") %>%
+   layer_activation("relu") %>%
+   layer_conv_2d(filter = 32, kernel_size = c(3,3)) %>%
+   layer_activation("relu") %>%
+   
+   layer_max_pooling_2d(pool_size = c(2,2)) %>%
+   layer_dropout(0.25) %>%
+   
+   layer_flatten() %>%
+   layer_dense(512) %>%
+   layer_activation("relu") %>%
+   layer_dropout(0.5) %>%
+   
+   layer_dense(1) %>%
+   layer_activation("sigmoid")
> 
> opt <- optimizer_rmsprop(lr = 0.0001, decay = 1e-6)
> 
> model %>% compile(
+   loss = "binary_crossentropy",
+   optimizer = opt,
+   metrics = "accuracy"
+ )
> 
> set.seed(1234)
> model %>% fit(X_train, y_train, epochs = 100, validation_data = list(X_val, y_val), batch_size = 32, verbose = 1)
C:\Users\Goutham\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
C:\Users\Goutham\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
C:\Users\Goutham\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
C:\Users\Goutham\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
C:\Users\Goutham\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
C:\Users\Goutham\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
C:\Users\Goutham\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
C:\Users\Goutham\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
C:\Users\Goutham\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
C:\Users\Goutham\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
C:\Users\Goutham\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
C:\Users\Goutham\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

2019-09-18 14:24:21.108820: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
Train on 15750 samples, validate on 1750 samples
Epoch 1/100
15750/15750 [==============================] - 53s 3ms/sample - loss: 0.3333 - acc: 0.8331 - val_loss: 0.2427 - val_acc: 0.8817
Epoch 2/100
15750/15750 [==============================] - 54s 3ms/sample - loss: 0.2479 - acc: 0.8791 - val_loss: 0.2898 - val_acc: 0.8611
Epoch 3/100
15750/15750 [==============================] - 52s 3ms/sample - loss: 0.2253 - acc: 0.8912 - val_loss: 0.1804 - val_acc: 0.9171
Epoch 4/100
15750/15750 [==============================] - 83s 5ms/sample - loss: 0.2033 - acc: 0.9062 - val_loss: 0.2876 - val_acc: 0.8703
Epoch 5/100
15750/15750 [==============================] - 52s 3ms/sample - loss: 0.1826 - acc: 0.9160 - val_loss: 0.1920 - val_acc: 0.9114
Epoch 6/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.1673 - acc: 0.9259 - val_loss: 0.1219 - val_acc: 0.9531
Epoch 7/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.1483 - acc: 0.9355 - val_loss: 0.0984 - val_acc: 0.9589
Epoch 8/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.1288 - acc: 0.9461 - val_loss: 0.0871 - val_acc: 0.9686
Epoch 9/100
15750/15750 [==============================] - 51s 3ms/sample - loss: 0.1106 - acc: 0.9547 - val_loss: 0.0763 - val_acc: 0.9657
Epoch 10/100
15750/15750 [==============================] - 52s 3ms/sample - loss: 0.0964 - acc: 0.9608 - val_loss: 0.0675 - val_acc: 0.9766
Epoch 11/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0891 - acc: 0.9650 - val_loss: 0.1011 - val_acc: 0.9594
Epoch 12/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0795 - acc: 0.9671 - val_loss: 0.0790 - val_acc: 0.9709
Epoch 13/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0732 - acc: 0.9712 - val_loss: 0.0447 - val_acc: 0.9829
Epoch 14/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0649 - acc: 0.9754 - val_loss: 0.0441 - val_acc: 0.9806
Epoch 15/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0605 - acc: 0.9770 - val_loss: 0.0442 - val_acc: 0.9823
Epoch 16/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0537 - acc: 0.9796 - val_loss: 0.0663 - val_acc: 0.9743
Epoch 17/100
15750/15750 [==============================] - 51s 3ms/sample - loss: 0.0498 - acc: 0.9808 - val_loss: 0.1643 - val_acc: 0.9360
Epoch 18/100
15750/15750 [==============================] - 51s 3ms/sample - loss: 0.0484 - acc: 0.9818 - val_loss: 0.0382 - val_acc: 0.9846
Epoch 19/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0435 - acc: 0.9837 - val_loss: 0.0437 - val_acc: 0.9829
Epoch 20/100
15750/15750 [==============================] - 53s 3ms/sample - loss: 0.0453 - acc: 0.9825 - val_loss: 0.0290 - val_acc: 0.9863
Epoch 21/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0383 - acc: 0.9860 - val_loss: 0.0258 - val_acc: 0.9891
Epoch 22/100
15750/15750 [==============================] - 51s 3ms/sample - loss: 0.0390 - acc: 0.9858 - val_loss: 0.0235 - val_acc: 0.9920
Epoch 23/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0344 - acc: 0.9870 - val_loss: 0.0435 - val_acc: 0.9823
Epoch 24/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0324 - acc: 0.9884 - val_loss: 0.0509 - val_acc: 0.9800
Epoch 25/100
15750/15750 [==============================] - 51s 3ms/sample - loss: 0.0314 - acc: 0.9881 - val_loss: 0.0209 - val_acc: 0.9943
Epoch 26/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0288 - acc: 0.9893 - val_loss: 0.0180 - val_acc: 0.9931
Epoch 27/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0282 - acc: 0.9895 - val_loss: 0.0282 - val_acc: 0.9891
Epoch 28/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0269 - acc: 0.9898 - val_loss: 0.0237 - val_acc: 0.9903
Epoch 29/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0251 - acc: 0.9907 - val_loss: 0.0264 - val_acc: 0.9897
Epoch 30/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0254 - acc: 0.9909 - val_loss: 0.0184 - val_acc: 0.9937
Epoch 31/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0249 - acc: 0.9907 - val_loss: 0.0206 - val_acc: 0.9926
Epoch 32/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0242 - acc: 0.9909 - val_loss: 0.0210 - val_acc: 0.9920
Epoch 33/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0210 - acc: 0.9926 - val_loss: 0.0160 - val_acc: 0.9949
Epoch 34/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0219 - acc: 0.9921 - val_loss: 0.0272 - val_acc: 0.9869
Epoch 35/100
15750/15750 [==============================] - 51s 3ms/sample - loss: 0.0225 - acc: 0.9926 - val_loss: 0.0238 - val_acc: 0.9903
Epoch 36/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0231 - acc: 0.9921 - val_loss: 0.0159 - val_acc: 0.9943
Epoch 37/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0167 - acc: 0.9937 - val_loss: 0.0171 - val_acc: 0.9926
Epoch 38/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0177 - acc: 0.9939 - val_loss: 0.0248 - val_acc: 0.9920
Epoch 39/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0170 - acc: 0.9940 - val_loss: 0.0513 - val_acc: 0.9857
Epoch 40/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0182 - acc: 0.9936 - val_loss: 0.0160 - val_acc: 0.9931
Epoch 41/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0155 - acc: 0.9945 - val_loss: 0.0168 - val_acc: 0.9954
Epoch 42/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0167 - acc: 0.9940 - val_loss: 0.0209 - val_acc: 0.9914
Epoch 43/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0154 - acc: 0.9947 - val_loss: 0.0244 - val_acc: 0.9914
Epoch 44/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0136 - acc: 0.9953 - val_loss: 0.0215 - val_acc: 0.9937
Epoch 45/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0147 - acc: 0.9947 - val_loss: 0.0156 - val_acc: 0.9949
Epoch 46/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0149 - acc: 0.9949 - val_loss: 0.0320 - val_acc: 0.9874
Epoch 47/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0136 - acc: 0.9955 - val_loss: 0.0206 - val_acc: 0.9949
Epoch 48/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0123 - acc: 0.9956 - val_loss: 0.0199 - val_acc: 0.9931
Epoch 49/100
15750/15750 [==============================] - 53s 3ms/sample - loss: 0.0127 - acc: 0.9956 - val_loss: 0.0301 - val_acc: 0.9897
Epoch 50/100
15750/15750 [==============================] - 54s 3ms/sample - loss: 0.0134 - acc: 0.9954 - val_loss: 0.0198 - val_acc: 0.9949
Epoch 51/100
15750/15750 [==============================] - 54s 3ms/sample - loss: 0.0119 - acc: 0.9954 - val_loss: 0.0192 - val_acc: 0.9954
Epoch 52/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0113 - acc: 0.9967 - val_loss: 0.0146 - val_acc: 0.9954
Epoch 53/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0117 - acc: 0.9958 - val_loss: 0.0178 - val_acc: 0.9960
Epoch 54/100
15750/15750 [==============================] - 51s 3ms/sample - loss: 0.0108 - acc: 0.9961 - val_loss: 0.0169 - val_acc: 0.9960
Epoch 55/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0113 - acc: 0.9953 - val_loss: 0.0154 - val_acc: 0.9960
Epoch 56/100
15750/15750 [==============================] - 51s 3ms/sample - loss: 0.0112 - acc: 0.9961 - val_loss: 0.0142 - val_acc: 0.9954
Epoch 57/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0100 - acc: 0.9963 - val_loss: 0.0329 - val_acc: 0.9886
Epoch 58/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0105 - acc: 0.9962 - val_loss: 0.0167 - val_acc: 0.9954
Epoch 59/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0085 - acc: 0.9971 - val_loss: 0.0178 - val_acc: 0.9954
Epoch 60/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0095 - acc: 0.9966 - val_loss: 0.0232 - val_acc: 0.9937
Epoch 61/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0091 - acc: 0.9969 - val_loss: 0.0176 - val_acc: 0.9954
Epoch 62/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0095 - acc: 0.9966 - val_loss: 0.0178 - val_acc: 0.9926
Epoch 63/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0100 - acc: 0.9966 - val_loss: 0.0191 - val_acc: 0.9931
Epoch 64/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0092 - acc: 0.9963 - val_loss: 0.0465 - val_acc: 0.9857
Epoch 65/100
15750/15750 [==============================] - 52s 3ms/sample - loss: 0.0071 - acc: 0.9970 - val_loss: 0.0160 - val_acc: 0.9943
Epoch 66/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0083 - acc: 0.9970 - val_loss: 0.0174 - val_acc: 0.9931
Epoch 67/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0091 - acc: 0.9975 - val_loss: 0.0170 - val_acc: 0.9943
Epoch 68/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0079 - acc: 0.9971 - val_loss: 0.0176 - val_acc: 0.9943
Epoch 69/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0091 - acc: 0.9964 - val_loss: 0.0169 - val_acc: 0.9954
Epoch 70/100
15750/15750 [==============================] - 51s 3ms/sample - loss: 0.0063 - acc: 0.9977 - val_loss: 0.0118 - val_acc: 0.9960
Epoch 71/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0107 - acc: 0.9970 - val_loss: 0.0506 - val_acc: 0.9846
Epoch 72/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0082 - acc: 0.9973 - val_loss: 0.0226 - val_acc: 0.9954
Epoch 73/100
15750/15750 [==============================] - 51s 3ms/sample - loss: 0.0075 - acc: 0.9973 - val_loss: 0.0160 - val_acc: 0.9960
Epoch 74/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0074 - acc: 0.9973 - val_loss: 0.0165 - val_acc: 0.9943
Epoch 75/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0354 - val_acc: 0.9909
Epoch 76/100
15750/15750 [==============================] - 53s 3ms/sample - loss: 0.0081 - acc: 0.9973 - val_loss: 0.0214 - val_acc: 0.9943
Epoch 77/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0086 - acc: 0.9971 - val_loss: 0.0325 - val_acc: 0.9903
Epoch 78/100
15750/15750 [==============================] - 48s 3ms/sample - loss: 0.0068 - acc: 0.9972 - val_loss: 0.0191 - val_acc: 0.9960
Epoch 79/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0050 - acc: 0.9983 - val_loss: 0.0260 - val_acc: 0.9960
Epoch 80/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0069 - acc: 0.9978 - val_loss: 0.0224 - val_acc: 0.9960
Epoch 81/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0078 - acc: 0.9973 - val_loss: 0.0251 - val_acc: 0.9954
Epoch 82/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0077 - acc: 0.9975 - val_loss: 0.0167 - val_acc: 0.9966
Epoch 83/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0063 - acc: 0.9975 - val_loss: 0.0206 - val_acc: 0.9954
Epoch 84/100
15750/15750 [==============================] - 48s 3ms/sample - loss: 0.0055 - acc: 0.9982 - val_loss: 0.0187 - val_acc: 0.9949
Epoch 85/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0053 - acc: 0.9979 - val_loss: 0.0352 - val_acc: 0.9903
Epoch 86/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0058 - acc: 0.9983 - val_loss: 0.0435 - val_acc: 0.9891
Epoch 87/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0268 - val_acc: 0.9966
Epoch 88/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0082 - acc: 0.9977 - val_loss: 0.0175 - val_acc: 0.9960
Epoch 89/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0055 - acc: 0.9980 - val_loss: 0.0345 - val_acc: 0.9926
Epoch 90/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0078 - acc: 0.9979 - val_loss: 0.0411 - val_acc: 0.9891
Epoch 91/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0060 - acc: 0.9983 - val_loss: 0.0182 - val_acc: 0.9954
Epoch 92/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0064 - acc: 0.9979 - val_loss: 0.0255 - val_acc: 0.9960
Epoch 93/100
15750/15750 [==============================] - 50s 3ms/sample - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0212 - val_acc: 0.9954
Epoch 94/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0070 - acc: 0.9982 - val_loss: 0.0245 - val_acc: 0.9937
Epoch 95/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0053 - acc: 0.9982 - val_loss: 0.0425 - val_acc: 0.9903
Epoch 96/100
15750/15750 [==============================] - 48s 3ms/sample - loss: 0.0068 - acc: 0.9980 - val_loss: 0.0194 - val_acc: 0.9960
Epoch 97/100
15750/15750 [==============================] - 48s 3ms/sample - loss: 0.0058 - acc: 0.9983 - val_loss: 0.0441 - val_acc: 0.9909
Epoch 98/100
15750/15750 [==============================] - 48s 3ms/sample - loss: 0.0069 - acc: 0.9980 - val_loss: 0.0196 - val_acc: 0.9954
Epoch 99/100
15750/15750 [==============================] - 48s 3ms/sample - loss: 0.0054 - acc: 0.9986 - val_loss: 0.0172 - val_acc: 0.9960
Epoch 100/100
15750/15750 [==============================] - 49s 3ms/sample - loss: 0.0045 - acc: 0.9983 - val_loss: 0.0185 - val_acc: 0.9949
> 
> y_test <- model %>% predict(X_test, batch_size = 32)
> 
> submission <- data.frame(id = test_ids$id, has_cactus = y_test)
> 
> write_csv(submission, 'submission.csv')
> 